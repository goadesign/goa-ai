package runtime

import (
	"context"
	"errors"
	"fmt"
	"strings"
	"time"

	"github.com/google/uuid"
	"goa.design/goa-ai/runtime/agent/engine"
	"goa.design/goa-ai/runtime/agent/hooks"
	"goa.design/goa-ai/runtime/agent/interrupt"
	"goa.design/goa-ai/runtime/agent/memory"
	"goa.design/goa-ai/runtime/agent/model"
	"goa.design/goa-ai/runtime/agent/planner"
	"goa.design/goa-ai/runtime/agent/policy"
	"goa.design/goa-ai/runtime/agent/run"
	"goa.design/goa-ai/runtime/agent/telemetry"
	"goa.design/goa-ai/runtime/agent/toolerrors"
	"goa.design/goa-ai/runtime/agent/tools"
)

const (
	// Minimal viable timeout for scheduling an activity. If remaining time is
	// less than or equal to this value, the runtime should not schedule new work.
	minActivityTimeout = 3 * time.Second

	// Minimal viable grace period for finalization. If remaining time is
	// less than or equal to this value, the runtime should finalize with a user-facing message.
	defaultFinalizerGrace = 10 * time.Second
)

// hardDeadlineCtxKey is a private context key used to propagate the parent
// hard deadline to nested inline agent runs.
type hardDeadlineCtxKey struct{}

type (
	// futureInfo bundles a Future with its associated tool call metadata for parallel execution.
	// When tools are launched asynchronously via ExecuteActivityAsync, we need to track the
	// future handle alongside the original call details and start time so we can correlate
	// results and measure duration when collecting completed activities.
	futureInfo struct {
		// future is the engine Future returned by ExecuteActivityAsync for this tool call.
		future engine.Future
		// call is the original tool request that was submitted for execution.
		call planner.ToolRequest
		// startTime records when the activity was scheduled, used to calculate tool duration.
		startTime time.Time
	}

	// turnSequencer tracks the turn ID and monotonic sequence counter for event ordering.
	// Each run maintains its own sequencer to ensure deterministic event ordering within
	// a conversational turn.
	turnSequencer struct {
		turnID   string
		sequence int
	}

	// childTracker tracks dynamically discovered child tool calls for a parent tool
	// (agent-as-tool pattern). As the planner discovers new child tools across iterations,
	// the tracker maintains the unique set of discovered IDs and triggers update events
	// when the count increases. This enables UI progress tracking ("3 of 5 complete").
	//
	// NOTE: This infrastructure is currently unused and reserved for future implementation
	// of nested agent-as-tool workflows where tools run their own internal planning loops
	// and dynamically discover child tools across multiple iterations. The struct and
	// methods are defined now to support future codegen and maintain API stability.
	childTracker struct {
		// parentToolCallID identifies the parent tool (usually an agent-as-tool invocation).
		parentToolCallID string
		// discovered maps tool call IDs to struct{} for efficient membership checking.
		// The map size is the current expected children total.
		discovered map[string]struct{}
		// lastExpectedTotal is the count last reported via ToolCallUpdatedEvent.
		// We only emit update events when len(discovered) > lastExpectedTotal.
		lastExpectedTotal int
	}
)

// ExecuteWorkflow is the main entry point for the generated workflow handler.
//
// Advanced & generated integration
//   - Intended to be invoked by code generated by goa-ai during agent
//     registration, or by advanced users writing custom engine adapters.
//   - Normal applications should prefer the high‑level AgentClient API
//     (Runtime.Client(...).Run/Start) rather than calling this directly.
//
// It executes the agent's plan/tool loop using the configured planner, policy,
// and runtime hooks. Returns the final agent output or an error if the workflow
// fails. Generated code calls this from the workflow handler registered with
// the engine.
func (r *Runtime) ExecuteWorkflow(wfCtx engine.WorkflowContext, input *RunInput) (*RunOutput, error) {
	if r.logger != nil {
		r.logger.Info(wfCtx.Context(), "ExecuteWorkflow called", "agent_id", input.AgentID, "run_id", input.RunID)
	}
	if input.AgentID == "" {
		return nil, errors.New("agent id is required")
	}
	defer r.storeWorkflowHandle(input.RunID, nil)
	reg, ok := r.agentByID(input.AgentID)
	if !ok {
		return nil, fmt.Errorf("agent %q is not registered", input.AgentID)
	}
	r.logger.Info(wfCtx.Context(), "Agent found, executing plan activity", "agent_id", input.AgentID)
	ctrl := interrupt.NewController(wfCtx)
	reader := r.memoryReader(wfCtx.Context(), input.AgentID, input.RunID)
	agentCtx := newAgentContext(agentContextOptions{
		runtime: r,
		agentID: input.AgentID,
		runID:   input.RunID,
		memory:  reader,
		turnID:  input.TurnID,
	})
	runCtx := run.Context{
		RunID:     input.RunID,
		SessionID: input.SessionID,
		TurnID:    input.TurnID,
		Attempt:   1,
		Labels:    input.Labels,
	}
	// Initialize turn sequencer for event ordering if TurnID is provided
	var seq *turnSequencer
	if input.TurnID != "" {
		seq = &turnSequencer{
			turnID: input.TurnID,
		}
	}
	r.publishHook(wfCtx.Context(), hooks.NewRunStartedEvent(input.RunID, input.AgentID, runCtx, *input), seq)
	r.recordRunStatus(wfCtx.Context(), input, run.StatusRunning, nil)
	defer r.publishHook(wfCtx.Context(), hooks.NewRunCompletedEvent(input.RunID, input.AgentID, "success", nil), seq)

	planInput := &planner.PlanInput{
		Messages:   input.Messages,
		RunContext: runCtx,
		Agent:      agentCtx,
		Events:     newPlannerEvents(r, input.AgentID, input.RunID),
	}
	// Compute deadlines before the initial Plan so it cannot outlive the run window.
	var (
		timeBudget     time.Duration
		budgetDeadline time.Time
		hardDeadline   time.Time
		grace          time.Duration
	)
	{
		timeBudget = time.Duration(0)
		if input.Policy != nil && input.Policy.TimeBudget > 0 {
			timeBudget = input.Policy.TimeBudget
		} else if reg.Policy.TimeBudget > 0 {
			timeBudget = reg.Policy.TimeBudget
		}
		switch {
		case input.Policy != nil && input.Policy.FinalizerGrace > 0:
			grace = input.Policy.FinalizerGrace
		case reg.Policy.FinalizerGrace > 0:
			grace = reg.Policy.FinalizerGrace
		default:
			grace = defaultFinalizerGrace
		}
		if timeBudget > 0 {
			budgetDeadline = wfCtx.Now().Add(timeBudget)
			hardDeadline = budgetDeadline.Add(grace)
		}
	}
	startReq := PlanActivityInput{
		AgentID:    input.AgentID,
		RunID:      input.RunID,
		Messages:   planInput.Messages,
		RunContext: planInput.RunContext,
	}
	// Apply run-level Plan timeout override when provided.
	planOpts := reg.PlanActivityOptions
	if input.Policy != nil && input.Policy.PlanTimeout > 0 {
		planOpts.Timeout = input.Policy.PlanTimeout
	}
	// Emit timing resolution for observability.
	if r.logger != nil {
		var planTimeout time.Duration
		if planOpts.Timeout > 0 {
			planTimeout = planOpts.Timeout
		}
		var toolTimeout time.Duration
		if input.Policy != nil && input.Policy.ToolTimeout > 0 {
			toolTimeout = input.Policy.ToolTimeout
		}
		r.logger.Info(wfCtx.Context(), "timing_resolved",
			"time_budget", timeBudget,
			"finalizer_grace", grace,
			"hard_deadline", hardDeadline,
			"plan_timeout", planTimeout,
			"tool_timeout", toolTimeout,
		)
	}
	result, err := r.runPlanActivity(wfCtx, reg.PlanActivityName, planOpts, startReq, hardDeadline)
	if err != nil {
		r.logger.Error(wfCtx.Context(), "Plan activity failed", "error", err)
		r.recordRunStatus(wfCtx.Context(), input, run.StatusFailed, map[string]any{
			"error": err.Error(),
		})
		return nil, err
	}
	if result == nil {
		r.logger.Error(wfCtx.Context(), "Plan activity returned nil result")
		r.recordRunStatus(wfCtx.Context(), input, run.StatusFailed, map[string]any{
			"error": "CRITICAL: Plan activity returned nil PlanResult",
		})
		return nil, fmt.Errorf("CRITICAL: Plan activity returned nil PlanResult")
	}
	r.logger.Info(wfCtx.Context(), "Plan activity completed", "tool_calls", len(result.ToolCalls), "final_response", result.FinalResponse != nil)
	// CRITICAL: Validate PlanResult structure - if planner returned ToolCalls, they should be present
	if len(result.ToolCalls) == 0 && result.FinalResponse == nil && result.Await == nil {
		r.recordRunStatus(wfCtx.Context(), input, run.StatusFailed, map[string]any{
			"error": "CRITICAL: PlanResult has no ToolCalls, FinalResponse, or Await",
		})
		return nil, fmt.Errorf("CRITICAL: PlanResult has no ToolCalls, FinalResponse, or Await - this should never happen")
	}
	// CRITICAL: If ToolCalls is empty but planner returned them, serialization may have failed
	if len(result.ToolCalls) == 0 && result.FinalResponse != nil {
		r.logger.Info(wfCtx.Context(), "PlanResult has FinalResponse but no ToolCalls - workflow will return early")
	}
	caps := initialCaps(reg.Policy)
	// Apply per-run cap overrides (run-level)
	if input.Policy != nil {
		if input.Policy.MaxToolCalls > 0 {
			caps.MaxToolCalls = input.Policy.MaxToolCalls
			caps.RemainingToolCalls = input.Policy.MaxToolCalls
		}
		if input.Policy.MaxConsecutiveFailedToolCalls > 0 {
			caps.MaxConsecutiveFailedToolCalls = input.Policy.MaxConsecutiveFailedToolCalls
			caps.RemainingConsecutiveFailedToolCalls = input.Policy.MaxConsecutiveFailedToolCalls
		}
	}
	// Deadlines (budgetDeadline, hardDeadline, grace) already computed above.
	nextAttempt := planInput.RunContext.Attempt + 1
	r.logger.Info(wfCtx.Context(), "Starting runLoop", "tool_calls", len(result.ToolCalls))
	out, err := r.runLoop(wfCtx, reg, input, planInput, result, caps, hardDeadline, nextAttempt, seq, nil, ctrl, grace)
	if err != nil {
		r.recordRunStatus(wfCtx.Context(), input, run.StatusFailed, map[string]any{
			"error": err.Error(),
		})
		return nil, err
	}
	r.recordRunStatus(wfCtx.Context(), input, run.StatusCompleted, nil)
	return out, nil
}

// runLoop executes the plan/tool/resume cycle until the planner returns a final response
// or a cap/deadline is exceeded. The seq parameter enables turn-based event sequencing.
func (r *Runtime) runLoop(
	wfCtx engine.WorkflowContext,
	reg AgentRegistration,
	input *RunInput,
	base *planner.PlanInput,
	initial *planner.PlanResult,
	caps policy.CapsState,
	deadline time.Time,
	nextAttempt int,
	seq *turnSequencer,
	parentTracker *childTracker,
	ctrl *interrupt.Controller,
	finalizerGrace time.Duration,
) (*RunOutput, error) {
	if base == nil {
		return nil, errors.New("base plan input is required")
	}
	ctx := wfCtx.Context()
	if r.logger == nil {
		r.logger = telemetry.NoopLogger{}
	}
	// Aggregate usage during the run via a temporary subscriber.
	var aggUsage model.TokenUsage
	usageSub := r.registerUsageAggregator(ctx, input.RunID, input.AgentID, &aggUsage)
	if usageSub != nil {
		defer func() {
			_ = usageSub.Close()
		}()
	}
	if initial == nil {
		return nil, fmt.Errorf("CRITICAL: runLoop initial PlanResult is nil")
	}
	if len(initial.ToolCalls) == 0 && initial.FinalResponse == nil && initial.Await == nil {
		return nil, fmt.Errorf("CRITICAL: runLoop initial PlanResult has no ToolCalls, FinalResponse, or Await")
	}
	r.logger.Info(ctx, "runLoop starting iteration", "tool_calls", len(initial.ToolCalls), "final_response", initial.FinalResponse != nil, "await", initial.Await != nil)
	result := initial
	// Derive per-run overrides for Resume and Tools.
	resumeOpts := reg.ResumeActivityOptions
	if input != nil && input.Policy != nil && input.Policy.PlanTimeout > 0 {
		resumeOpts.Timeout = input.Policy.PlanTimeout
	}
	toolOpts := reg.ExecuteToolActivityOptions
	if input != nil && input.Policy != nil && input.Policy.ToolTimeout > 0 {
		toolOpts.Timeout = input.Policy.ToolTimeout
	}
	var lastToolResults []*planner.ToolResult
	for {
		r.logger.Info(ctx, "runLoop iteration", "tool_calls", len(result.ToolCalls), "final_response", result.FinalResponse != nil, "await", result.Await != nil)
		if err := r.handleInterrupts(wfCtx, input, base, seq, ctrl, &nextAttempt); err != nil {
			return nil, err
		}
		// When a hard deadline is set, stop scheduling new work when the remaining time
		// is less than or equal to the grace period; request finalization instead.
		if !deadline.IsZero() {
			now := wfCtx.Now()
			remaining := deadline.Sub(now)
			if finalizerGrace > 0 && remaining <= finalizerGrace {
				return r.finalizeWithPlanner(wfCtx, reg, input, base, lastToolResults, nextAttempt, seq, planner.TerminationReasonTimeBudget, deadline)
			}
			if finalizerGrace == 0 && remaining <= minActivityTimeout {
				// No configured grace; avoid scheduling work that cannot complete meaningfully.
				return r.finalizeWithPlanner(wfCtx, reg, input, base, lastToolResults, nextAttempt, seq, planner.TerminationReasonTimeBudget, deadline)
			}
			if remaining <= 0 {
				// Time budget fully exhausted (including grace): try to finalize.
				// This may still race with engine TTLs, but provides a best-effort reply.
				return r.finalizeWithPlanner(wfCtx, reg, input, base, lastToolResults, nextAttempt, seq, planner.TerminationReasonTimeBudget, deadline)
			}
		}
		if !deadline.IsZero() && wfCtx.Now().After(deadline) {
			// Redundant guard; kept for clarity with prior semantics.
			return r.finalizeWithPlanner(wfCtx, reg, input, base, lastToolResults, nextAttempt, seq, planner.TerminationReasonTimeBudget, deadline)
		}
		// Handle Await: publish await event, pause and wait for external input.
		if result.Await != nil {
			r.logger.Info(ctx, "PlanResult has Await, handling await")
			if ctrl == nil {
				return nil, errors.New("await not supported in inline runs")
			}
			// Publish paused event with a reason.
			reason := "await_external"
			if result.Await.Clarification != nil {
				reason = "await_clarification"
			}
			// If planner provided structured await info, emit a typed await event first.
			if result.Await.Clarification != nil {
				c := result.Await.Clarification
				r.publishHook(ctx, hooks.NewAwaitClarificationEvent(
					base.RunContext.RunID, base.Agent.ID(), c.ID, c.Question, c.MissingFields, c.RestrictToTool, c.ExampleInput,
				), seq)
			} else if result.Await.ExternalTools != nil {
				e := result.Await.ExternalTools
				items := make([]hooks.AwaitToolItem, 0, len(e.Items))
				for _, it := range e.Items {
					items = append(items, hooks.AwaitToolItem{
						ToolName:   it.Name,
						ToolCallID: it.ToolCallID,
						Payload:    it.Payload,
					})
				}
				r.publishHook(ctx, hooks.NewAwaitExternalToolsEvent(
					base.RunContext.RunID, base.Agent.ID(), e.ID, items,
				), seq)
			}
			r.publishHook(ctx, hooks.NewRunPausedEvent(base.RunContext.RunID, base.Agent.ID(), reason, "runtime", nil, nil), seq)
			// Block until the appropriate provide signal arrives.
			if result.Await.Clarification != nil {
				ans, err := ctrl.WaitProvideClarification(ctx)
				if err != nil {
					return nil, err
				}
				// Validate await ID when provided
				if c := result.Await.Clarification; c != nil && c.ID != "" && ans.ID != "" && ans.ID != c.ID {
					return nil, errors.New("unexpected await ID for clarification")
				}
				// Append the answer as a user message and continue planning.
				if ans.Answer != "" {
					base.Messages = append(base.Messages, &planner.AgentMessage{
						Role:    "user",
						Content: ans.Answer,
					})
				}
				// Set running and emit resumed
				r.recordRunStatus(ctx, input, run.StatusRunning, map[string]any{
					"resumed_by": "clarification",
				})
				r.publishHook(ctx, hooks.NewRunResumedEvent(base.RunContext.RunID, base.Agent.ID(), "clarification_provided", ans.RunID, ans.Labels, 1), seq)
				// Immediately PlanResume
				resumeCtx := base.RunContext
				resumeCtx.Attempt = nextAttempt
				nextAttempt++
				resumeReq := PlanActivityInput{
					AgentID:     base.Agent.ID(),
					RunID:       base.RunContext.RunID,
					Messages:    base.Messages,
					RunContext:  resumeCtx,
					ToolResults: nil,
				}
				var err2 error
				result, err2 = r.runPlanActivity(wfCtx, reg.ResumeActivityName, resumeOpts, resumeReq, deadline)
				if err2 != nil {
					return nil, err2
				}
				continue
			} else if result.Await.ExternalTools != nil {
				rs, err := ctrl.WaitProvideToolResults(ctx)
				if err != nil {
					return nil, err
				}
				// Validate await ID when provided
				if e := result.Await.ExternalTools; e != nil && e.ID != "" && rs.ID != "" && rs.ID != e.ID {
					return nil, errors.New("unexpected await ID for external tools")
				}
				// Feed results into next PlanResume turn directly.
				lastToolResults = rs.Results
				// Advance to PlanResume immediately without executing internal tools.
				resumeCtx := base.RunContext
				resumeCtx.Attempt = nextAttempt
				nextAttempt++
				resumeReq := PlanActivityInput{
					AgentID:     base.Agent.ID(),
					RunID:       base.RunContext.RunID,
					Messages:    base.Messages,
					RunContext:  resumeCtx,
					ToolResults: lastToolResults,
				}
				// Set running and emit resumed
				r.recordRunStatus(ctx, input, run.StatusRunning, map[string]any{
					"resumed_by": "tool_results",
					"results":    len(lastToolResults),
				})
				r.publishHook(ctx, hooks.NewRunResumedEvent(base.RunContext.RunID, base.Agent.ID(), "tool_results_provided", input.RunID, nil, 0), seq)
				var err2 error
				result, err2 = r.runPlanActivity(wfCtx, reg.ResumeActivityName, resumeOpts, resumeReq, deadline)
				if err2 != nil {
					return nil, err2
				}
				continue
			}
		}

		r.logger.Info(ctx, "Checking result.ToolCalls", "len", len(result.ToolCalls))

		if len(result.ToolCalls) == 0 {
			r.logger.Info(ctx, "No tool calls, checking FinalResponse")
			if result.FinalResponse == nil {
				r.logger.Error(ctx, "ERROR - Neither tool calls nor final response!")
				// CRITICAL: This error will be visible in workflow failure logs
				return nil, fmt.Errorf("CRITICAL: planner returned neither tool calls nor final response - ToolCalls=%d, FinalResponse=%v, Await=%v", len(result.ToolCalls), result.FinalResponse != nil, result.Await != nil)
			}
			r.publishHook(
				ctx,
				hooks.NewAssistantMessageEvent(
					base.RunContext.RunID,
					base.Agent.ID(),
					result.FinalResponse.Message.Content,
					nil,
				),
				seq,
			)
			for _, note := range result.Notes {
				r.publishHook(
					ctx,
					hooks.NewPlannerNoteEvent(
						base.RunContext.RunID,
						base.Agent.ID(),
						note.Text,
						note.Labels,
					),
					seq,
				)
			}
			notes := make([]*planner.PlannerAnnotation, len(result.Notes))
			for i := range result.Notes {
				notes[i] = &result.Notes[i]
			}
			return &RunOutput{
				AgentID:    base.Agent.ID(),
				RunID:      base.RunContext.RunID,
				Final:      &result.FinalResponse.Message,
				ToolEvents: lastToolResults,
				Notes:      notes,
				Usage:      &aggUsage,
			}, nil
		}

		if caps.RemainingToolCalls == 0 && caps.MaxToolCalls > 0 {
			// Tool cap exhausted: request a final tool-free response from the planner.
			return r.finalizeWithPlanner(wfCtx, reg, input, base, lastToolResults, nextAttempt, seq, planner.TerminationReasonToolCap, deadline)
		}
		if !deadline.IsZero() && wfCtx.Now().After(deadline) {
			// Time budget exceeded after evaluating caps/policy
			return r.finalizeWithPlanner(
				wfCtx,
				reg,
				input,
				base,
				lastToolResults,
				nextAttempt,
				seq,
				planner.TerminationReasonTimeBudget,
				deadline,
			)
		}
		// Start with candidate tool calls from the planner.
		candidates := result.ToolCalls

		// If the planner provided an assistant message alongside tool calls,
		// append it to the conversation so the next turn has proper context.
		if result.AssistantMessage != nil {
			base.Messages = append(base.Messages, result.AssistantMessage)
			r.publishHook(
				ctx,
				hooks.NewAssistantMessageEvent(
					base.RunContext.RunID,
					base.Agent.ID(),
					result.AssistantMessage.Content,
					nil,
				),
				seq,
			)
		}

		r.logger.Info(ctx, "Workflow received tool calls from planner", "count", len(candidates))
		// Apply per-run policy overrides (restrict tool and tag filters) before policy decision.
		if ov := input.Policy; ov != nil && (ov.RestrictToTool != "" || len(ov.AllowedTags) > 0 || len(ov.DeniedTags) > 0) && len(candidates) > 0 {
			r.logger.Info(ctx, "Applying per-run policy overrides", "restrict_to_tool", ov.RestrictToTool, "allowed_tags", ov.AllowedTags, "denied_tags", ov.DeniedTags)
			metas := r.toolMetadata(candidates)
			filtered := make([]planner.ToolRequest, 0, len(candidates))
			for i, call := range candidates {
				// RestrictToTool
				if ov.RestrictToTool != "" && call.Name != ov.RestrictToTool {
					r.logger.Info(ctx, "Tool filtered by RestrictToTool", "tool", call.Name)
					continue
				}
				// Tag allow/deny checks
				ok := true
				if len(ov.AllowedTags) > 0 || len(ov.DeniedTags) > 0 {
					tags := metas[i].Tags
					if len(ov.AllowedTags) > 0 {
						if !hasIntersection(tags, ov.AllowedTags) {
							r.logger.Info(ctx, "Tool filtered by AllowedTags", "tool", call.Name, "tags", tags, "required", ov.AllowedTags)
							ok = false
						}
					}
					if ok && len(ov.DeniedTags) > 0 {
						if hasIntersection(tags, ov.DeniedTags) {
							r.logger.Info(ctx, "Tool filtered by DeniedTags", "tool", call.Name, "tags", tags, "denied", ov.DeniedTags)
							ok = false
						}
					}
				}
				if ok {
					filtered = append(filtered, call)
				}
			}
			candidates = filtered
			r.logger.Info(ctx, "After per-run policy filtering", "candidates", len(candidates))
		}
		allowed := candidates
		if r.Policy != nil {
			r.logger.Info(ctx, "Applying runtime policy decision")
			decision, err := r.Policy.Decide(ctx, policy.Input{
				RunContext:    base.RunContext,
				Tools:         r.toolMetadata(candidates),
				RetryHint:     toPolicyRetryHint(result.RetryHint),
				RemainingCaps: caps,
				Requested:     toolHandles(candidates),
				Labels:        base.RunContext.Labels,
			})
			if err != nil {
				return nil, err
			}
			if len(decision.Labels) > 0 {
				base.RunContext.Labels = mergeLabels(base.RunContext.Labels, decision.Labels)
				input.Labels = mergeLabels(input.Labels, decision.Labels)
			}
			if decision.DisableTools {
				return nil, errors.New("tool execution disabled by policy")
			}
			if len(decision.AllowedTools) > 0 {
				allowed = filterToolCalls(allowed, decision.AllowedTools)
			}
			caps = mergeCaps(caps, decision.Caps)
			r.recordPolicyDecision(ctx, input, decision)
			r.publishHook(ctx, hooks.NewPolicyDecisionEvent(
				base.RunContext.RunID,
				base.Agent.ID(),
				decision.AllowedTools,
				caps,
				cloneLabels(decision.Labels),
				cloneMetadata(decision.Metadata),
			), seq)
		}
		if len(allowed) == 0 {
			r.logger.Error(ctx, "ERROR - No tools allowed for execution after filtering", "candidates", len(result.ToolCalls))
			return nil, errors.New("no tools allowed for execution")
		}
		r.logger.Info(ctx, "Executing allowed tool calls", "count", len(allowed))
		if parentTracker != nil {
			ids := collectToolCallIDs(allowed)
			if len(ids) > 0 && parentTracker.registerDiscovered(ids) {
				r.publishHook(ctx,
					hooks.NewToolCallUpdatedEvent(
						base.RunContext.RunID,
						base.Agent.ID(),
						parentTracker.parentToolCallID,
						parentTracker.currentTotal(),
					),
					seq,
				)
				parentTracker.markUpdated()
			}
		}
		// Per-turn max cap from overrides (applies before remaining run caps)
		if input.Policy != nil && input.Policy.PerTurnMaxToolCalls > 0 && len(allowed) > input.Policy.PerTurnMaxToolCalls {
			allowed = allowed[:input.Policy.PerTurnMaxToolCalls]
		}
		if caps.MaxToolCalls > 0 && caps.RemainingToolCalls < len(allowed) {
			allowed = allowed[:caps.RemainingToolCalls]
		}
		for i := range allowed {
			if allowed[i].RunID == "" {
				allowed[i].RunID = base.RunContext.RunID
			}
			if allowed[i].SessionID == "" {
				allowed[i].SessionID = base.RunContext.SessionID
			}
			if allowed[i].TurnID == "" {
				allowed[i].TurnID = base.RunContext.TurnID
			}
			// Assign deterministic tool-call IDs and inherit parent when tracking children.
			if allowed[i].ToolCallID == "" {
				allowed[i].ToolCallID = generateDeterministicToolCallID(
					base.RunContext.RunID, base.RunContext.TurnID, allowed[i].Name, i,
				)
			}
			if parentTracker != nil && allowed[i].ParentToolCallID == "" {
				allowed[i].ParentToolCallID = parentTracker.parentToolCallID
			}
		}
		// Group allowed calls by per-tool timeout to apply overrides without changing executor API.
		var grouped [][]planner.ToolRequest
		var timeouts []time.Duration
		if input != nil && input.Policy != nil && len(input.Policy.PerToolTimeout) > 0 {
			buckets := make(map[time.Duration][]planner.ToolRequest)
			resolve := func(name tools.Ident) (time.Duration, bool) {
				for k, v := range input.Policy.PerToolTimeout {
					kn := string(k)
					n := string(name)
					if strings.HasSuffix(kn, "*") {
						prefix := strings.TrimSuffix(kn, "*")
						if strings.HasPrefix(n, prefix) {
							return v, true
						}
					} else if kn == n {
						return v, true
					}
				}
				return 0, false
			}
			for _, call := range allowed {
				if to, ok := resolve(call.Name); ok && to > 0 {
					buckets[to] = append(buckets[to], call)
				} else {
					// Use default bucket (use current toolOpts.Timeout)
					buckets[toolOpts.Timeout] = append(buckets[toolOpts.Timeout], call)
				}
			}
			for to, calls := range buckets {
				grouped = append(grouped, calls)
				timeouts = append(timeouts, to)
			}
		} else {
			grouped = [][]planner.ToolRequest{allowed}
			timeouts = []time.Duration{toolOpts.Timeout}
		}
		var vals []*planner.ToolResult
		for i := range grouped {
			opt := toolOpts
			if timeouts[i] > 0 {
				opt.Timeout = timeouts[i]
			}
			sub, err := r.executeToolCalls(
				wfCtx, reg.ExecuteToolActivity, opt, base.RunContext.RunID, base.Agent.ID(),
				grouped[i], result.ExpectedChildren, seq, parentTracker, deadline,
			)
			if err != nil {
				return nil, err
			}
			vals = append(vals, sub...)
		}
		// Directly use pointer results for the planner input
		lastToolResults = vals
		// Decrement cap by the number of tool calls executed, not the number of results returned.
		// This ensures the cap is properly decremented even if some results are missing.
		caps.RemainingToolCalls = decrementCap(caps.RemainingToolCalls, len(allowed))
		if failures(vals) > 0 {
			caps.RemainingConsecutiveFailedToolCalls = decrementCap(
				caps.RemainingConsecutiveFailedToolCalls, failures(vals),
			)
			if caps.MaxConsecutiveFailedToolCalls > 0 && caps.RemainingConsecutiveFailedToolCalls <= 0 {
				// Consecutive failure cap exhausted: request finalization.
				return r.finalizeWithPlanner(wfCtx, reg, input, base, lastToolResults, nextAttempt, seq, planner.TerminationReasonFailureCap, deadline)
			}
		} else if caps.MaxConsecutiveFailedToolCalls > 0 {
			caps.RemainingConsecutiveFailedToolCalls = caps.MaxConsecutiveFailedToolCalls
		}

		// Apply missing-fields policy if configured. The helper may finalize or pause/resume.
		if out, err := r.handleMissingFieldsPolicy(wfCtx, reg, input, base, vals, &nextAttempt, seq, ctrl); err != nil {
			return nil, err
		} else if out != nil {
			return out, nil
		}

		// Hard protection: If this turn executed agent-as-tool calls
		// and they produced zero child tool calls in total, do not
		// resume. Finalize immediately to avoid loops.
		{
			var agentToolCount int
			var totalChildren int
			toolNames := make([]tools.Ident, 0, len(vals))
			for _, tr := range vals {
				// Identify agent-tools by spec metadata
				if spec, ok := r.toolSpec(tr.Name); ok && spec.IsAgentTool {
					agentToolCount++
					toolNames = append(toolNames, tr.Name)
					if tr.ChildrenCount > 0 {
						totalChildren += tr.ChildrenCount
					}
				}
			}
			if agentToolCount > 0 && totalChildren == 0 {
				// Emit a clear observability signal before finalization.
				r.publishHook(ctx,
					hooks.NewHardProtectionEvent(
						base.RunContext.RunID,
						base.Agent.ID(),
						"agent_tool_no_children",
						agentToolCount,
						totalChildren,
						toolNames,
					),
					seq,
				)
				return r.finalizeWithPlanner(wfCtx, reg, input, base, lastToolResults, nextAttempt, seq, planner.TerminationReasonFailureCap, deadline)
			}
		}

		resumeCtx := base.RunContext
		resumeCtx.Attempt = nextAttempt
		nextAttempt++
		resumeReq := PlanActivityInput{
			AgentID:     base.Agent.ID(),
			RunID:       base.RunContext.RunID,
			Messages:    base.Messages,
			RunContext:  resumeCtx,
			ToolResults: lastToolResults,
		}
		res, rerr := r.runPlanActivity(wfCtx, reg.ResumeActivityName, resumeOpts, resumeReq, deadline)
		if rerr != nil {
			return nil, rerr
		}
		result = res
	}
}

// handleMissingFieldsPolicy inspects tool results for a RetryHint indicating missing
// required fields and applies the agent RunPolicy.OnMissingFields behavior:
//
//   - MissingFieldsFinalize: immediately finalize by requesting a tool-free final answer
//     from the planner. Returns a non-nil RunOutput to short-circuit the loop.
//   - MissingFieldsAwaitClarification: when durable (interrupt controller present), emit
//     an await_clarification event and pause the run. On resume, appends the user answer
//     as a message to the base PlanInput so the next turn can proceed. Returns handled=true.
//   - MissingFieldsResume (or unspecified): do nothing; the planner will see RetryHints
//     and may choose how to proceed. Returns handled=false.
//
// The function returns:
//   - out: non-nil only when finalization occurred
//   - handled: true when a pause/resume cycle was performed
//   - err: any error encountered while pausing/resuming
func (r *Runtime) handleMissingFieldsPolicy(
	wfCtx engine.WorkflowContext,
	reg AgentRegistration,
	input *RunInput,
	base *planner.PlanInput,
	results []*planner.ToolResult,
	nextAttempt *int,
	seq *turnSequencer,
	ctrl *interrupt.Controller,
) (*RunOutput, error) {
	if ctrl == nil || reg.Policy.OnMissingFields == "" {
		return nil, nil
	}
	ctx := wfCtx.Context()
	// Find first result with missing-fields hint and capture tool context.
	var (
		mf          *planner.RetryHint
		triggerTool tools.Ident
		triggerCall string
	)
	for _, tr := range results {
		if tr == nil || tr.RetryHint == nil {
			continue
		}
		if tr.RetryHint.Reason == planner.RetryReasonMissingFields || len(tr.RetryHint.MissingFields) > 0 {
			mf = tr.RetryHint
			triggerTool = tr.Name
			triggerCall = tr.ToolCallID
			break
		}
	}
	if mf == nil {
		return nil, nil
	}
	switch reg.Policy.OnMissingFields {
	case MissingFieldsFinalize:
		out, err := r.finalizeWithPlanner(wfCtx, reg, input, base, results, *nextAttempt, seq, planner.TerminationReasonFailureCap, time.Time{})
		return out, err
	case MissingFieldsAwaitClarification:
		// Generate deterministic await ID for correlation safety.
		awaitID := generateDeterministicAwaitID(base.RunContext.RunID, base.RunContext.TurnID, triggerTool, triggerCall)
		var restrict tools.Ident
		if mf.RestrictToTool {
			restrict = mf.Tool
		}
		r.publishHook(ctx, hooks.NewAwaitClarificationEvent(
			base.RunContext.RunID,
			base.Agent.ID(),
			awaitID,
			mf.ClarifyingQuestion,
			mf.MissingFields,
			restrict,
			mf.ExampleInput,
		), seq)
		r.publishHook(ctx, hooks.NewRunPausedEvent(base.RunContext.RunID, base.Agent.ID(), "await_clarification", "runtime", nil, nil), seq)
		ans, err := ctrl.WaitProvideClarification(ctx)
		if err != nil {
			return nil, err
		}
		// Validate correlation when ID is present on the answer.
		if ans.ID != "" && ans.ID != awaitID {
			return nil, fmt.Errorf("unexpected await ID for clarification")
		}
		if ans.Answer != "" {
			base.Messages = append(base.Messages, &planner.AgentMessage{
				Role:    "user",
				Content: ans.Answer,
			})
		}
		r.recordRunStatus(ctx, input, run.StatusRunning, map[string]any{
			"resumed_by": "clarification",
		})
		r.publishHook(ctx, hooks.NewRunResumedEvent(base.RunContext.RunID, base.Agent.ID(), "clarification_provided", input.RunID, ans.Labels, 1), seq)
		return nil, nil
	case MissingFieldsResume:
		return nil, nil
	default:
		return nil, nil
	}
}

// finalizeWithPlanner asks the planner for a tool-free final response and returns it as RunOutput.
func (r *Runtime) finalizeWithPlanner(
	wfCtx engine.WorkflowContext,
	reg AgentRegistration,
	input *RunInput,
	base *planner.PlanInput,
	lastToolResults []*planner.ToolResult,
	nextAttempt int,
	seq *turnSequencer,
	reason planner.TerminationReason,
	hardDeadline time.Time,
) (*RunOutput, error) {
	if base == nil {
		return nil, errors.New("base plan input is required")
	}
	ctx := wfCtx.Context()
	// Prepare a brief message to steer planners that incorporate system messages.
	var hint string
	switch reason {
	case planner.TerminationReasonTimeBudget:
		hint = "Time budget reached. Provide the best possible final answer now. Do not call any tools."
	case planner.TerminationReasonToolCap:
		hint = "Tool budget exhausted. Provide the best possible final answer now. Do not call any tools."
	case planner.TerminationReasonFailureCap:
		hint = "Too many tool failures. Provide the best possible final answer now. Do not call any tools."
	default:
		hint = "Provide the best possible final answer now. Do not call any tools."
	}
	messages := base.Messages
	if hint != "" {
		messages = append(messages, &planner.AgentMessage{Role: "system", Content: hint})
	}
	resumeCtx := base.RunContext
	resumeCtx.Attempt = nextAttempt
	// Signal zero remaining duration for any prompt engineering that uses MaxDuration
	resumeCtx.MaxDuration = "0s"
	req := PlanActivityInput{
		AgentID:     base.Agent.ID(),
		RunID:       base.RunContext.RunID,
		Messages:    messages,
		RunContext:  resumeCtx,
		ToolResults: lastToolResults,
		Finalize:    &planner.Termination{Reason: reason, Message: hint},
	}
	// Emit a pause/resume pair to indicate a finalization turn began.
	r.publishHook(ctx, hooks.NewRunPausedEvent(base.RunContext.RunID, base.Agent.ID(), "finalize", "runtime", map[string]string{"reason": string(reason)}, nil), seq)
	r.recordRunStatus(ctx, input, run.StatusRunning, map[string]any{"resumed_by": "finalize"})
	r.publishHook(ctx, hooks.NewRunResumedEvent(base.RunContext.RunID, base.Agent.ID(), "finalize", input.RunID, nil, 0), seq)

	// Human‑readable reason strings for error contexts when finalization fails.
	reasonText := func() string {
		switch reason {
		case planner.TerminationReasonTimeBudget:
			return "time budget exceeded"
		case planner.TerminationReasonToolCap:
			return "tool call cap exceeded"
		case planner.TerminationReasonFailureCap:
			return "consecutive failed tool call cap exceeded"
		default:
			return "finalization failed"
		}
	}()

	// Apply run-level Plan timeout override to Resume if present.
	resumeOpts := reg.ResumeActivityOptions
	if input != nil && input.Policy != nil && input.Policy.PlanTimeout > 0 {
		resumeOpts.Timeout = input.Policy.PlanTimeout
	}
	result, err := r.runPlanActivity(wfCtx, reg.ResumeActivityName, resumeOpts, req, hardDeadline)
	if err != nil {
		// Surface the termination reason prominently; include underlying error for observability.
		return nil, fmt.Errorf("%s: %w", reasonText, err)
	}
	if result == nil || result.FinalResponse == nil {
		return nil, fmt.Errorf("%s", reasonText)
	}
	r.publishHook(
		ctx,
		hooks.NewAssistantMessageEvent(
			base.RunContext.RunID,
			base.Agent.ID(),
			result.FinalResponse.Message.Content,
			nil,
		),
		seq,
	)
	for _, note := range result.Notes {
		r.publishHook(
			ctx,
			hooks.NewPlannerNoteEvent(
				base.RunContext.RunID,
				base.Agent.ID(),
				note.Text,
				note.Labels,
			),
			seq,
		)
	}
	notes := make([]*planner.PlannerAnnotation, len(result.Notes))
	for i := range result.Notes {
		notes[i] = &result.Notes[i]
	}
	return &RunOutput{
		AgentID:    base.Agent.ID(),
		RunID:      base.RunContext.RunID,
		Final:      &result.FinalResponse.Message,
		ToolEvents: lastToolResults,
		Notes:      notes,
		// Usage aggregation continues to be recorded by the surrounding loop
	}, nil
}

func (r *Runtime) handleInterrupts(
	wfCtx engine.WorkflowContext,
	input *RunInput,
	base *planner.PlanInput,
	seq *turnSequencer,
	ctrl *interrupt.Controller,
	nextAttempt *int,
) error {
	if ctrl == nil {
		return nil
	}
	ctx := wfCtx.Context()
	for {
		req, ok := ctrl.PollPause()
		if !ok {
			break
		}
		r.recordRunStatus(ctx, input, run.StatusPaused, map[string]any{
			"reason": req.Reason,
		})
		r.publishHook(
			ctx,
			hooks.NewRunPausedEvent(
				input.RunID,
				input.AgentID,
				req.Reason,
				req.RequestedBy,
				req.Labels,
				req.Metadata,
			),
			seq,
		)

		resumeReq, err := ctrl.WaitResume(ctx)
		if err != nil {
			return err
		}
		if len(resumeReq.Messages) > 0 {
			base.Messages = append(base.Messages, resumeReq.Messages...)
		}
		base.RunContext.Attempt = *nextAttempt
		*nextAttempt++
		r.recordRunStatus(ctx, input, run.StatusRunning, map[string]any{
			"resumed_by": resumeReq.RequestedBy,
		})
		r.publishHook(
			ctx,
			hooks.NewRunResumedEvent(
				input.RunID,
				input.AgentID,
				resumeReq.Notes,
				resumeReq.RequestedBy,
				resumeReq.Labels,
				len(resumeReq.Messages),
			),
			seq,
		)
	}
	return nil
}

// executeToolCalls schedules tool activities in parallel and collects their results.
// Tools are launched asynchronously via ExecuteActivityAsync, then results are collected
// in order. This provides better performance for independent tool calls while maintaining
// deterministic result ordering. expectedChildren indicates how many child tools are expected
// to be discovered dynamically by the tools in this batch (0 if not tracked).
func collectToolCallIDs(calls []planner.ToolRequest) []string {
	ids := make([]string, 0, len(calls))
	for _, call := range calls {
		ids = append(ids, call.ToolCallID)
	}
	return ids
}

func (r *Runtime) executeToolCalls(
	wfCtx engine.WorkflowContext,
	activityName string, toolActOptions engine.ActivityOptions, runID, agentID string,
	calls []planner.ToolRequest,
	expectedChildren int,
	seq *turnSequencer,
	parentTracker *childTracker,
	hardDeadline time.Time,
) ([]*planner.ToolResult, error) {
	if activityName == "" {
		return nil, errors.New("execute tool activity not registered")
	}
	ctx := wfCtx.Context()

	// Decide per-call execution path (inline vs activity) by toolset.
	// Inline toolsets run synchronously within the workflow loop; others schedule
	// activities and collect futures. Results are returned in call order.
	futures := make([]futureInfo, 0, len(calls))
	discoveredIDs := make([]string, 0, len(calls))
	inlineResults := make([]*planner.ToolResult, 0)
	for i, call := range calls {
		if call.ToolCallID == "" {
			call.ToolCallID = generateDeterministicToolCallID(runID, call.TurnID, call.Name, i)
			calls[i] = call
		}
		if parentTracker != nil && call.ParentToolCallID == "" {
			call.ParentToolCallID = parentTracker.parentToolCallID
			calls[i] = call
		}

		spec, hasSpec := r.toolSpec(call.Name)
		if !hasSpec {
			return nil, fmt.Errorf("unknown tool %q", call.Name)
		}
		ts, hasTS := r.toolsets[spec.Toolset]

		// Prepare scheduled event (queue filled only for activity execution)
		queue := ""
		if hasTS && ts.TaskQueue != "" {
			queue = ts.TaskQueue
		}
		r.publishHook(ctx,
			hooks.NewToolCallScheduledEvent(
				runID, agentID, call.Name, call.ToolCallID, call.Payload, queue,
				call.ParentToolCallID, expectedChildren,
			),
			seq,
		)

		if hasTS && ts.Inline {
			// Execute inline, preserving workflow context on ctx for agent-as-tool
			start := wfCtx.Now()
			// Propagate hard deadline to nested agent via context for effective capping.
			parentCtx := context.WithValue(ctx, hardDeadlineCtxKey{}, hardDeadline)
			ctxWithWF := engine.WithWorkflowContext(parentCtx, wfCtx)
			res, err := ts.Execute(ctxWithWF, &call)
			if err != nil {
				return nil, fmt.Errorf("tool %q inline execution failed: %w", call.Name, err)
			}
			if res == nil {
				return nil, fmt.Errorf("tool %q inline execution returned nil result", call.Name)
			}
			// Ensure correlation fields are populated so results can be merged
			// back to their originating calls.
			if res.Name == "" {
				res.Name = call.Name
			}
			if res.ToolCallID == "" {
				res.ToolCallID = call.ToolCallID
			}
			duration := wfCtx.Now().Sub(start)
			// Telemetry builder support can be applied post-aggregation where needed.
			// Always emit the parent tool result event; child events suppression applies
			// to nested child tool calls, not the parent tool completion.
			var evtErr *toolerrors.ToolError
			if res.Error != nil {
				evtErr = res.Error
			}
			r.publishHook(ctx,
				hooks.NewToolResultReceivedEvent(
					runID,
					agentID,
					call.Name,
					call.ToolCallID,
					call.ParentToolCallID,
					res.Result,
					duration,
					res.Telemetry,
					evtErr,
				),
				seq,
			)
			// Accumulate result preserving order
			inlineResults = append(inlineResults, res)
			if parentTracker != nil {
				discoveredIDs = append(discoveredIDs, call.ToolCallID)
			}
			continue
		}

		// Activity path (default)
		rawPayload, err := r.marshalToolValue(ctx, call.Name, call.Payload, true)
		if err != nil {
			return nil, err
		}
		req := engine.ActivityRequest{
			Name: activityName,
			Input: ToolInput{
				AgentID:          agentID,
				RunID:            runID,
				ToolsetName:      spec.Toolset,
				ToolName:         call.Name,
				ToolCallID:       call.ToolCallID,
				Payload:          rawPayload,
				SessionID:        call.SessionID,
				TurnID:           call.TurnID,
				ParentToolCallID: call.ParentToolCallID,
			},
		}
		// Apply strong-contract execute_tool options first
		if toolActOptions.Queue != "" {
			req.Queue = toolActOptions.Queue
		}
		// Apply timeout: start with configured, then cap to remaining time to hard deadline.
		timeout := toolActOptions.Timeout
		if !hardDeadline.IsZero() {
			now := wfCtx.Now()
			if rem := hardDeadline.Sub(now); rem > 0 {
				if timeout == 0 || timeout > rem {
					timeout = rem
				}
			}
		}
		if timeout > 0 {
			req.Timeout = timeout
		}
		if !isZeroRetryPolicy(toolActOptions.RetryPolicy) {
			req.RetryPolicy = toolActOptions.RetryPolicy
		}
		// If no queue specified via options, allow explicit toolset TaskQueue to set it
		if req.Queue == "" && hasTS && ts.TaskQueue != "" {
			req.Queue = ts.TaskQueue
		}
		future, err := wfCtx.ExecuteActivityAsync(ctx, req)
		if err != nil {
			return nil, fmt.Errorf("failed to schedule tool %q: %w", call.Name, err)
		}
		futures = append(futures, futureInfo{
			future:    future,
			call:      call,
			startTime: wfCtx.Now(),
		})
		if parentTracker != nil {
			discoveredIDs = append(discoveredIDs, call.ToolCallID)
		}
	}

	if parentTracker != nil && parentTracker.registerDiscovered(discoveredIDs) && parentTracker.needsUpdate() {
		r.publishHook(
			ctx,
			hooks.NewToolCallUpdatedEvent(runID, agentID, parentTracker.parentToolCallID, parentTracker.currentTotal()),
			seq,
		)
		parentTracker.markUpdated()
	}

	// Collect all results in order
	results := make([]*planner.ToolResult, 0, len(calls))
	// First, append inline results in the same order they were executed relative to calls.
	// We'll merge activity results preserving call order below.
	// To keep ordering simple, we build a map from ToolCallID to inline result.
	inlineByID := make(map[string]*planner.ToolResult, len(inlineResults))
	for _, ir := range inlineResults {
		if ir != nil {
			inlineByID[ir.ToolCallID] = ir
		}
	}
	// Collect activity results
	activityByID := make(map[string]*planner.ToolResult, len(futures))
	for _, info := range futures {
		var out ToolOutput
		if err := info.future.Get(ctx, &out); err != nil {
			return nil, fmt.Errorf("tool %q failed: %w", info.call.Name, err)
		}

		duration := wfCtx.Now().Sub(info.startTime)
		// Decode tool result. If decoding fails (mismatch with generated result
		// type), do not abort the workflow. Forward the raw payload to preserve
		// observability and allow clients to render best‑effort data.
		var decoded any
		if len(out.Payload) > 0 {
			if v, decErr := r.unmarshalToolValue(ctx, info.call.Name, out.Payload, false); decErr == nil {
				decoded = v
			} else {
				decoded = out.Payload
			}
		}

		toolRes := &planner.ToolResult{
			Name:       info.call.Name,
			Result:     decoded,
			ToolCallID: info.call.ToolCallID,
			Telemetry:  out.Telemetry,
		}
		var toolErr *planner.ToolError
		if out.Error != "" {
			toolErr = planner.NewToolError(out.Error)
			toolRes.Error = toolErr
		}
		if out.RetryHint != nil {
			toolRes.RetryHint = out.RetryHint
		}

		r.publishHook(
			ctx,
			hooks.NewToolResultReceivedEvent(
				runID,
				agentID,
				info.call.Name,
				info.call.ToolCallID,
				info.call.ParentToolCallID,
				decoded,
				duration,
				out.Telemetry,
				toolErr,
			),
			seq,
		)

		activityByID[info.call.ToolCallID] = toolRes
	}

	// Merge results following original call order (inline or activity)
	for _, call := range calls {
		if ir, ok := inlineByID[call.ToolCallID]; ok {
			results = append(results, ir)
			continue
		}
		if ar, ok := activityByID[call.ToolCallID]; ok {
			results = append(results, ar)
			continue
		}
		// Should not happen; defensive: keep order consistent even if missing.
		r.logWarn(ctx, "missing tool result for call", fmt.Errorf("no result"), "tool", call.Name, "tool_call_id", call.ToolCallID)
	}

	return results, nil
}

// runPlanActivity schedules a plan/resume activity with the configured options.
func (r *Runtime) runPlanActivity(
	wfCtx engine.WorkflowContext, activityName string, options engine.ActivityOptions, input PlanActivityInput, hardDeadline time.Time,
) (*planner.PlanResult, error) {
	if activityName == "" {
		return nil, errors.New("plan activity not registered")
	}
	var out PlanActivityOutput
	req := engine.ActivityRequest{
		Name:  activityName,
		Input: input,
	}
	if options.Queue != "" {
		req.Queue = options.Queue
	}
	// Apply timeout: start with configured, then cap to remaining time to hard deadline.
	timeout := options.Timeout
	if !hardDeadline.IsZero() {
		now := wfCtx.Now()
		if rem := hardDeadline.Sub(now); rem > 0 {
			if timeout == 0 || timeout > rem {
				timeout = rem
			}
		}
	}
	if timeout > 0 {
		req.Timeout = timeout
	}
	if !isZeroRetryPolicy(options.RetryPolicy) {
		req.RetryPolicy = options.RetryPolicy
	}
	if err := wfCtx.ExecuteActivity(wfCtx.Context(), req, &out); err != nil {
		return nil, err
	}
	if out.Result == nil {
		return nil, fmt.Errorf("CRITICAL: runPlanActivity received nil PlanResult")
	}
	if len(out.Result.ToolCalls) == 0 && out.Result.FinalResponse == nil && out.Result.Await == nil {
		return nil, fmt.Errorf("CRITICAL: runPlanActivity received PlanResult with no ToolCalls, FinalResponse, or Await")
	}
	r.logger.Info(wfCtx.Context(), "runPlanActivity received PlanResult", "tool_calls", len(out.Result.ToolCalls), "final_response", out.Result.FinalResponse != nil, "await", out.Result.Await != nil)
	return out.Result, nil
}

// recordRunStatus upserts run metadata to the store if configured.
func (r *Runtime) recordRunStatus(ctx context.Context, input *RunInput, status run.Status, meta map[string]any) {
	if r.RunStore == nil {
		return
	}
	rec := run.Record{
		AgentID:   input.AgentID,
		RunID:     input.RunID,
		SessionID: input.SessionID,
		TurnID:    input.TurnID,
		Status:    status,
		StartedAt: time.Now(),
		UpdatedAt: time.Now(),
		Labels:    cloneLabels(input.Labels),
		Metadata:  meta,
	}
	if err := r.RunStore.Upsert(ctx, rec); err != nil {
		r.logWarn(ctx, "run record upsert failed", err)
	}
}

func (r *Runtime) recordPolicyDecision(ctx context.Context, input *RunInput, decision policy.Decision) {
	if r.RunStore == nil {
		return
	}
	rec, err := r.RunStore.Load(ctx, input.RunID)
	if err != nil {
		r.logWarn(ctx, "run record load failed", err, "run_id", input.RunID)
		return
	}
	now := time.Now()
	if rec.RunID == "" {
		rec.AgentID = input.AgentID
		rec.RunID = input.RunID
		rec.SessionID = input.SessionID
		rec.TurnID = input.TurnID
		rec.StartedAt = now
	}
	if rec.StartedAt.IsZero() {
		rec.StartedAt = now
	}
	rec.AgentID = input.AgentID
	rec.SessionID = input.SessionID
	rec.TurnID = input.TurnID
	rec.Status = run.StatusRunning
	rec.UpdatedAt = now
	rec.Labels = mergeLabels(rec.Labels, input.Labels)

	entry := map[string]any{
		"caps":      decision.Caps,
		"timestamp": now.UTC(),
	}
	if len(decision.AllowedTools) > 0 {
		entry["allowed_tools"] = decision.AllowedTools
	}
	if len(decision.Labels) > 0 {
		entry["labels"] = cloneLabels(decision.Labels)
	}
	if len(decision.Metadata) > 0 {
		entry["metadata"] = cloneMetadata(decision.Metadata)
	}
	if decision.DisableTools {
		entry["disable_tools"] = true
	}

	meta := cloneMetadata(rec.Metadata)
	meta = appendPolicyDecisionMetadata(meta, entry)
	rec.Metadata = meta

	if err := r.RunStore.Upsert(ctx, rec); err != nil {
		r.logWarn(ctx, "policy decision upsert failed", err)
	}
}

// registerUsageAggregator subscribes to Usage events for a specific run/agent and
// aggregates token usage into the provided accumulator. Returns a subscription
// handle that should be closed by the caller. If the bus is nil or registration
// fails, returns nil.
func (r *Runtime) registerUsageAggregator(
	ctx context.Context,
	runID string,
	agentID string,
	agg *model.TokenUsage,
) hooks.Subscription {
	if r.Bus == nil {
		return nil
	}
	sub, err := r.Bus.Register(hooks.SubscriberFunc(func(c context.Context, evt hooks.Event) error {
		if evt.RunID() != runID || evt.AgentID() != agentID {
			return nil
		}
		if u, ok := evt.(*hooks.UsageEvent); ok {
			*agg = model.TokenUsage{
				InputTokens:  agg.InputTokens + u.InputTokens,
				OutputTokens: agg.OutputTokens + u.OutputTokens,
				TotalTokens:  agg.TotalTokens + u.TotalTokens,
			}
		}
		return nil
	}))
	if err != nil {
		r.logWarn(ctx, "usage subscriber register failed", err)
		return nil
	}
	return sub
}

// memoryReader loads the run snapshot from the memory store and wraps it in a Reader.
func (r *Runtime) memoryReader(ctx context.Context, agentID, runID string) memory.Reader {
	if r.Memory == nil {
		return emptyMemoryReader{}
	}
	snapshot, err := r.Memory.LoadRun(ctx, agentID, runID)
	if err != nil {
		return emptyMemoryReader{}
	}
	return newMemoryReader(snapshot.Events)
}

// generateRunID creates a unique run identifier by combining the agent ID and a UUID.
func generateRunID(agentID string) string {
	prefix := strings.ReplaceAll(agentID, ".", "-")
	return fmt.Sprintf("%s-%s", prefix, uuid.NewString())
}

// nextSeq increments and returns the next sequence number for this turn.
func (t *turnSequencer) nextSeq() int {
	seq := t.sequence
	t.sequence++
	return seq
}
